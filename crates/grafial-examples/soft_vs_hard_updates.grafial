// Example: Soft Updates vs Hard Constraints
// Demonstrates the key difference: Bayesian updates preserve uncertainty,
// while hard constraints would eliminate it. This is critical for probabilistic reasoning.

schema ResourceAllocation {
  node Resource {
    allocation: Real
    capacity: Real
  }
  edge ALLOCATED_TO { }
}

belief_model AllocationBeliefs on ResourceAllocation {
  node Resource {
    // Uncertain allocation: we observe usage but it's noisy
    allocation ~ Gaussian(mean=0.5, precision=0.1)  // Weak prior - high uncertainty
    capacity ~ Gaussian(mean=1.0, precision=1.0)
  }
  edge ALLOCATED_TO {
    exist ~ Bernoulli(prior=0.2, weight=5.0)
  }
}

evidence InitialAllocation on AllocationBeliefs {
  // Initial observations with uncertainty
  Resource { 
    "R1" { allocation: 0.6 },
    "R2" { allocation: 0.4 },
    "R3" { allocation: 0.8 }
  }
  
  ALLOCATED_TO(Resource -> Resource) { "R1" -> "R1" }
}

// Rule that does SOFT updates: preserves uncertainty while shifting mean
rule BalanceAllocation on AllocationBeliefs {
  pattern
    (A:Resource)-[ab:ALLOCATED_TO]->(B:Resource)
  
  where
    prob(ab) >= 0.7
    and E[A.allocation] > 0.8
    and E[B.allocation] < 0.5
  
  action {
    // SOFT UPDATE: non_bayesian_nudge(... variance=preserve) shifts the posterior mean while preserving precision
    // This is NOT a full Bayesian update - it's a manual intervention for control actions
    //
    // Mechanically: updates μ while keeping τ (precision) unchanged
    // - Before: value ~ N(μ_old, τ)
    // - After: value ~ N(μ_new, τ)  ← same variance, different mean
    //
    // Use cases:
    // - Control actions (rebalancing, adjustments)
    // - Policy enforcement (soft constraints)
    // - Counterfactual reasoning
    //
    // For true Bayesian evidence incorporation, use observe statements instead
    let transfer = (E[A.allocation] - E[B.allocation]) * 0.2
    non_bayesian_nudge A.allocation to E[A.allocation] - transfer variance=preserve
    non_bayesian_nudge B.allocation to E[B.allocation] + transfer variance=preserve // Compare to alternatives:
    // 1. Hard constraint (not supported): A.allocation = 0.7 → eliminates uncertainty
    // 2. Bayesian observation: observe A.allocation = 0.7 → combines with prior
    // 3. non_bayesian_nudge(... variance=preserve) (used here): sets mean directly, preserves variance
  }
  
  mode: for_each
}

// Rule that uses delete ... confidence=high: sets edge probability to near-zero
// But this is still probabilistic (not exactly zero)
rule DisconnectOverloaded on AllocationBeliefs {
  pattern
    (A:Resource)-[ab:ALLOCATED_TO]->(B:Resource)
  
  where
    prob(ab) >= 0.5
    and E[A.allocation] > 0.9
    and E[B.allocation] > 0.9
  
  action {
    // delete ... confidence=high: sets edge to Beta(1, 10⁶) → P(exist) ≈ 0.000001
    // Properties:
    // - NOT exactly zero (still a valid probability distribution)
    // - Highly concentrated: variance ≈ 10⁻¹²
    // - Theoretically updatable: strong evidence could shift belief
    // - In practice: effectively removes edge from consideration
    //
    // This is a finite approximation to a deterministic constraint
    // Preserves probabilistic semantics while achieving near-determinism
    delete ab confidence=high
  }
  
  mode: for_each
}

flow AllocationFlow on AllocationBeliefs {
  graph initial = from_evidence InitialAllocation
  
  // Soft updates: rebalance while preserving uncertainty
  graph balanced = initial |> apply_rule BalanceAllocation
  
  // Hard actions: disconnect overloaded resources
  graph disconnected = balanced |> apply_rule DisconnectOverloaded
  
  // Metrics that understand uncertainty
  metric avg_allocation = nodes(Resource) |> avg(by=E[node.allocation])
  
  // Can compute probability of overload
  metric overload_risk = nodes(Resource) |> avg(by=E[node.allocation] / E[node.capacity])
  
  export disconnected as "final_allocation"
}
