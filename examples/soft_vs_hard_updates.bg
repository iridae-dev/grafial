// Example: Soft Updates vs Hard Constraints
// Demonstrates the key difference: Bayesian updates preserve uncertainty,
// while hard constraints would eliminate it. This is critical for probabilistic reasoning.

schema ResourceAllocation {
  node Resource {
    allocation: Real
    capacity: Real
  }
  edge ALLOCATED_TO { }
}

belief_model AllocationBeliefs on ResourceAllocation {
  node Resource {
    // Uncertain allocation: we observe usage but it's noisy
    allocation ~ GaussianPosterior(
      prior_mean=0.5,
      prior_precision=0.1  // Weak prior - high uncertainty
    )
    capacity ~ GaussianPosterior(
      prior_mean=1.0,
      prior_precision=1.0
    )
  }
  edge ALLOCATED_TO {
    exist ~ BernoulliPosterior(prior=0.2, pseudo_count=5.0)
  }
}

evidence InitialAllocation on AllocationBeliefs {
  // Initial observations with uncertainty
  observe Resource["R1"].allocation = 0.6
  observe Resource["R2"].allocation = 0.4
  observe Resource["R3"].allocation = 0.8
  
  observe edge ALLOCATED_TO(Resource["R1"], Resource["R1"]) present
}

// Rule that does SOFT updates: preserves uncertainty while shifting mean
rule BalanceAllocation on AllocationBeliefs {
  pattern
    (A:Resource)-[ab:ALLOCATED_TO]->(B:Resource)
  
  where
    prob(ab) >= 0.7
    and E[A.allocation] > 0.8
    and E[B.allocation] < 0.5
  
  action {
    // SOFT UPDATE: set_expectation shifts the posterior mean while preserving precision
    // This is NOT a full Bayesian update - it's a manual intervention for control actions
    //
    // Mechanically: updates μ while keeping τ (precision) unchanged
    // - Before: value ~ N(μ_old, τ)
    // - After: value ~ N(μ_new, τ)  ← same variance, different mean
    //
    // Use cases:
    // - Control actions (rebalancing, adjustments)
    // - Policy enforcement (soft constraints)
    // - Counterfactual reasoning
    //
    // For true Bayesian evidence incorporation, use observe statements instead
    let transfer = (E[A.allocation] - E[B.allocation]) * 0.2
    set_expectation A.allocation = E[A.allocation] - transfer
    set_expectation B.allocation = E[B.allocation] + transfer

    // Compare to alternatives:
    // 1. Hard constraint (not supported): A.allocation = 0.7 → eliminates uncertainty
    // 2. Bayesian observation: observe A.allocation = 0.7 → combines with prior
    // 3. set_expectation (used here): sets mean directly, preserves variance
  }
  
  mode: for_each
}

// Rule that uses force_absent: sets edge probability to near-zero
// But this is still probabilistic (not exactly zero)
rule DisconnectOverloaded on AllocationBeliefs {
  pattern
    (A:Resource)-[ab:ALLOCATED_TO]->(B:Resource)
  
  where
    prob(ab) >= 0.5
    and E[A.allocation] > 0.9
    and E[B.allocation] > 0.9
  
  action {
    // force_absent: sets edge to Beta(1, 10⁶) → P(exist) ≈ 0.000001
    // Properties:
    // - NOT exactly zero (still a valid probability distribution)
    // - Highly concentrated: variance ≈ 10⁻¹²
    // - Theoretically updatable: strong evidence could shift belief
    // - In practice: effectively removes edge from consideration
    //
    // This is a finite approximation to a deterministic constraint
    // Preserves probabilistic semantics while achieving near-determinism
    force_absent ab
  }
  
  mode: for_each
}

flow AllocationFlow on AllocationBeliefs {
  graph initial = from_evidence InitialAllocation
  
  // Soft updates: rebalance while preserving uncertainty
  graph balanced = initial |> apply_rule BalanceAllocation
  
  // Hard actions: disconnect overloaded resources
  graph disconnected = balanced |> apply_rule DisconnectOverloaded
  
  // Metrics that understand uncertainty
  metric avg_allocation = sum_nodes(
    label=Resource,
    contrib=E[node.allocation]
  ) / count_nodes(label=Resource)
  
  // Can compute probability of overload
  metric overload_risk = sum_nodes(
    label=Resource,
    contrib=E[node.allocation] / E[node.capacity]
  ) / count_nodes(label=Resource)
  
  export disconnected as "final_allocation"
}

