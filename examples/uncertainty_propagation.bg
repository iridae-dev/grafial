// Example: Uncertainty Propagation Through Evidence
// Demonstrates how Bayesian updates accumulate evidence and how rules
// can reason probabilistically when information is incomplete

schema FraudDetection {
  node Transaction {
    amount: Real
    risk_score: Real
  }
  edge SUSPICIOUS { }
}

belief_model FraudBeliefs on FraudDetection {
  node Transaction {
    // Prior: most transactions are safe (low risk)
    risk_score ~ GaussianPosterior(
      prior_mean=0.2,
      prior_precision=0.1  // Weak prior - uncertain initially
    )
    amount ~ GaussianPosterior(
      prior_mean=100.0,
      prior_precision=0.01
    )
  }
  edge SUSPICIOUS {
    // Rare event: only 1% of transactions are suspicious
    exist ~ BernoulliPosterior(
      prior=0.01,
      pseudo_count=100.0  // Strong prior - requires strong evidence to shift
    )
  }
}

evidence InitialEvidence on FraudBeliefs {
  // First observation: transaction amount
  observe Transaction["T1"].amount = 5000.0
  
  // Second observation: risk score (from external model)
  observe Transaction["T1"].risk_score = 0.8
  
  // Note: We haven't observed the edge yet, but we can still reason about it
}

evidence AdditionalEvidence on FraudBeliefs {
  // Later: more evidence comes in
  observe Transaction["T1"].risk_score = 0.9  // Updates posterior mean
  
  // Now we have direct edge evidence
  observe edge SUSPICIOUS(Transaction["T1"], Transaction["T1"]) present
  
  // But notice: even with strong prior (0.01), one observation doesn't
  // make it certain - posterior is still uncertain
}

// Rule that reasons probabilistically: flag transactions that are
// likely (but not certain) to be suspicious
rule FlagHighRisk on FraudBeliefs {
  pattern
    (T:Transaction)-[s:SUSPICIOUS]->(T)
  
  where
    // Probabilistic threshold: flag if P(suspicious) > 0.3
    // This is a soft decision, not a hard boolean
    prob(s) >= 0.3
    or E[T.risk_score] > 0.7
    or (E[T.amount] > 10000.0 and E[T.risk_score] > 0.5)
  
  action {
    // Soft update: increase risk score but preserve uncertainty
    // This is different from a hard constraint - we're updating beliefs
    set_expectation T.risk_score = E[T.risk_score] * 1.1
  }
  
  mode: for_each
}

flow FraudAnalysis on FraudBeliefs {
  graph initial = from_evidence InitialEvidence
  graph with_additional = from_evidence AdditionalEvidence
  
  // Compare: how did probabilities change with more evidence?
  graph flagged = with_additional |> apply_rule FlagHighRisk
  
  // Metrics that reason about uncertainty
  metric avg_risk = sum_nodes(label=Transaction, contrib=E[node.risk_score]) / count_nodes(label=Transaction)
  // Note: Can't directly sum probabilities in metrics - would need to match edges first
  // This demonstrates the limitation: metrics operate on nodes, not edges directly
  
  export flagged as "flagged_transactions"
}

